{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinBERT Example Notebook\n",
    "\n",
    "This notebooks shows how to train and use the FinBERT pre-trained language model for financial sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:04.902740Z",
     "start_time": "2020-03-23T15:55:04.876252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ce2e9558c130>:21: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from finbert.finbert import *\n",
    "import finbert.utils as tools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:05.711210Z",
     "start_time": "2020-03-23T15:55:05.693609Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting path variables:\n",
    "1. `lm_path`: the path for the pre-trained language model (If vanilla Bert is used then no need to set this one).\n",
    "2. `cl_path`: the path where the classification model is saved.\n",
    "3. `cl_data_path`: the path of the directory that contains the data files of `train.csv`, `validation.csv`, `test.csv`.\n",
    "---\n",
    "\n",
    "In the initialization of `bertmodel`, we can either use the original pre-trained weights from Google by giving `bm = 'bert-base-uncased`, or our further pre-trained language model by `bm = lm_path`\n",
    "\n",
    "\n",
    "---\n",
    "All of the configurations with the model is controlled with the `config` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:07.405597Z",
     "start_time": "2020-03-23T15:55:07.386378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_path: /home/rrmorris/project/ucsd-mle/finBERT/models/language_model/finbertTRC2\n",
      "cl_path: /home/rrmorris/project/ucsd-mle/finBERT/models/classifier_model/finbert-sentiment\n",
      "cl_data_path: /home/rrmorris/project/ucsd-mle/finBERT/data/sentiment_data\n"
     ]
    }
   ],
   "source": [
    "lm_path = project_dir/'models'/'language_model'/'finbertTRC2'\n",
    "cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n",
    "cl_data_path = project_dir/'data'/'sentiment_data'\n",
    "print('lm_path: {}'.format(lm_path))\n",
    "print('cl_path: {}'.format(cl_path))\n",
    "print('cl_data_path: {}'.format(cl_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configuring training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the explanations of the training parameters in the class docsctrings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:12.378583Z",
     "start_time": "2020-03-23T15:55:09.196746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Clean the cl_path\n",
    "#try:\n",
    "#    shutil.rmtree(cl_path) \n",
    "#except:\n",
    "#    pass\n",
    "\n",
    "#bertmodel = AutoModelForSequenceClassification.from_pretrained(lm_path,cache_dir=None, num_labels=3)\n",
    "bertmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased',cache_dir=None, num_labels=3)\n",
    "\n",
    "\n",
    "config = Config(   data_dir=cl_data_path,\n",
    "                   bert_model=bertmodel,\n",
    "                   num_train_epochs=4,\n",
    "                   model_dir=cl_path,\n",
    "                   max_seq_length = 48,\n",
    "                   train_batch_size = 32,\n",
    "                   learning_rate = 2e-5,\n",
    "                   output_mode='classification',\n",
    "                   warm_up_proportion=0.2,\n",
    "                   local_rank=-1,\n",
    "                   discriminate=True,\n",
    "                   gradual_unfreeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`finbert` is our main class that encapsulates all the functionality. The list of class labels should be given in the prepare_model method call with label_list parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:16.657078Z",
     "start_time": "2020-03-23T15:55:16.639644Z"
    }
   },
   "outputs": [],
   "source": [
    "finbert = FinBert(config)\n",
    "finbert.base_model = 'bert-base-uncased'\n",
    "finbert.config.discriminate=True\n",
    "finbert.config.gradual_unfreeze=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:17.850734Z",
     "start_time": "2020-03-23T15:55:17.368073Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:09:17 - INFO - finbert.finbert -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "finbert.prepare_model(label_list=['positive','negative','neutral'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:19.395707Z",
     "start_time": "2020-03-23T15:55:19.349642Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the training examples\n",
    "train_data = finbert.get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:25.912424Z",
     "start_time": "2020-03-23T15:55:20.065887Z"
    }
   },
   "outputs": [],
   "source": [
    "model = finbert.create_the_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Fine-tune only a subset of the model\n",
    "The variable `freeze` determines the last layer (out of 12) to be freezed. You can skip this part if you want to fine-tune the whole model.\n",
    "\n",
    "<span style=\"color:red\">Important: </span>\n",
    "Execute this step if you want a shorter training time in the expense of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for fine-tuning a subset of the model.\n",
    "\n",
    "freeze = 6\n",
    "\n",
    "for param in model.bert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for i in range(freeze):\n",
    "    for param in model.bert.encoder.layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:35.486890Z",
     "start_time": "2020-03-23T15:55:27.293772Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:08 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   guid: train-1\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   tokens: [CLS] damn , i would also really rather bt ##c over airline miles [SEP]\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   input_ids: 101 4365 1010 1045 2052 2036 2428 2738 18411 2278 2058 8582 2661 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:08 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/08/2021 22:16:08 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:08 - INFO - finbert.finbert -     Num examples = 719\n",
      "06/08/2021 22:16:08 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:08 - INFO - finbert.finbert -     Num steps = 8\n",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1e50ad498c45ebbce365dc4c1757a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:11 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   guid: validation-1\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   tokens: [CLS] bt ##c is the root of this market . [SEP]\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   input_ids: 101 18411 2278 2003 1996 7117 1997 2023 3006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:11 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/08/2021 22:16:11 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:11 - INFO - finbert.finbert -     Num examples = 80\n",
      "06/08/2021 22:16:11 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:11 - INFO - finbert.finbert -     Num steps = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e50a510bce46f3b4a6b13b5884d747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [0.9105482896169027]\n",
      "No best model found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 1/4 [00:03<00:11,  3.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b841b837b2412e9b6b4336dbcc79d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:16 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   guid: validation-1\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   tokens: [CLS] bt ##c is the root of this market . [SEP]\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   input_ids: 101 18411 2278 2003 1996 7117 1997 2023 3006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:16 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/08/2021 22:16:16 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:16 - INFO - finbert.finbert -     Num examples = 80\n",
      "06/08/2021 22:16:16 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:16 - INFO - finbert.finbert -     Num steps = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6af09088634710a17dad7f155de342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [0.9105482896169027, 0.9105482896169027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 2/4 [00:08<00:08,  4.42s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5387ce2cd5b4fd8a6343e25c5524512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:22 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   guid: validation-1\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   tokens: [CLS] bt ##c is the root of this market . [SEP]\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   input_ids: 101 18411 2278 2003 1996 7117 1997 2023 3006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:22 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/08/2021 22:16:22 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:22 - INFO - finbert.finbert -     Num examples = 80\n",
      "06/08/2021 22:16:22 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:22 - INFO - finbert.finbert -     Num steps = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b65bc3dc454461a86d8545194d1a769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [0.9105482896169027, 0.9105482896169027, 0.9105482896169027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 3/4 [00:14<00:05,  5.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcf64c78e734ca7b4b77bdf82970df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:28 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   guid: validation-1\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   tokens: [CLS] bt ##c is the root of this market . [SEP]\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   input_ids: 101 18411 2278 2003 1996 7117 1997 2023 3006 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:28 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/08/2021 22:16:28 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:28 - INFO - finbert.finbert -     Num examples = 80\n",
      "06/08/2021 22:16:28 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:28 - INFO - finbert.finbert -     Num steps = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b2bf3e52d44ffa8c657a685f11e82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [0.9105482896169027, 0.9105482896169027, 0.9105482896169027, 0.9105482896169027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:20<00:00,  5.24s/it]\n"
     ]
    }
   ],
   "source": [
    "trained_model = finbert.train(train_examples = train_data, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "`bert.evaluate` outputs the DataFrame, where true labels and logit values for each example is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:40.056789Z",
     "start_time": "2020-03-23T15:58:40.023198Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = finbert.get_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:48.248044Z",
     "start_time": "2020-03-23T15:58:41.699009Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:16:53 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   guid: test-1\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   tokens: [CLS] second wave will be taking over ether ##eum chain . [SEP]\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   input_ids: 101 2117 4400 2097 2022 2635 2058 28855 14820 4677 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:16:53 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -     Num examples = 200\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -     Num steps = 24\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -     Num examples = 200\n",
      "06/08/2021 22:16:53 - INFO - finbert.finbert -     Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bd2c195dcc450caebefebb21f74203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = finbert.evaluate(examples=test_data, model=trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:51.361079Z",
     "start_time": "2020-03-23T15:58:51.339548Z"
    }
   },
   "outputs": [],
   "source": [
    "def report(df, cols=['label','prediction','logits']):\n",
    "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
    "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
    "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
    "    print(\"Loss:{0:.2f}\".format(loss))\n",
    "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(df[cols[0]], df[cols[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:53.190447Z",
     "start_time": "2020-03-23T15:58:53.166729Z"
    }
   },
   "outputs": [],
   "source": [
    "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:54.436270Z",
     "start_time": "2020-03-23T15:58:54.399174Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.89\n",
      "Accuracy:0.56\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.56      0.45        45\n",
      "           1       0.31      0.64      0.42        22\n",
      "           2       0.82      0.56      0.66       133\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.51      0.58      0.51       200\n",
      "weighted avg       0.67      0.56      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(results,cols=['labels','prediction','predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `predict` function, given a piece of text, we split it into a list of sentences and then predict sentiment for each sentence. The output is written into a dataframe. Predictions are represented in three different columns: \n",
    "\n",
    "1) `logit`: probabilities for each class\n",
    "\n",
    "2) `prediction`: predicted label\n",
    "\n",
    "3) `sentiment_score`: sentiment score calculated as: probability of positive - probability of negative\n",
    "\n",
    "Below we analyze a paragraph taken out of [this](https://www.economist.com/finance-and-economics/2019/01/03/a-profit-warning-from-apple-jolts-markets) article from The Economist. For comparison purposes, we also put the sentiments predicted with TextBlob.\n",
    "> Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. The news rapidly infected financial markets. Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened. The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. Yields on government bonds fell as investors fled to the traditional haven in a market storm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:03.875213Z",
     "start_time": "2020-03-23T15:59:03.857612Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Bitcoin’s price has fallen to its lowest point in over a week as traders \\\n",
    "stare down prospects of shifting U.S. monetary policy and continued tightening of \\\n",
    "regulation of cryptocurrencies in China. Other notable cryptos were also trading in \\\n",
    "the red, with the top 10 by market capitalization having fallen between 7.3% and \\\n",
    "12.9% over the previous 24 hours. Polkadot and XRP were the hardest hit, down 12.93% \\\n",
    "and 11.39%, respectively.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:16.246963Z",
     "start_time": "2020-03-23T15:59:13.285393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cl_path, cache_dir=None, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rrmorris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:19.531663Z",
     "start_time": "2020-03-23T15:59:17.744984Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:20:22 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   guid: 0\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   tokens: [CLS] bit ##co ##in ’ s price has fallen to its lowest point in over a week as traders stare down prospects of shifting u . s . monetary policy and continued tightening of regulation of crypt ##oc ##ur ##ren ##cies in china . [SEP]\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   input_ids: 101 2978 3597 2378 1521 1055 3976 2038 5357 2000 2049 7290 2391 1999 2058 1037 2733 2004 13066 6237 2091 16746 1997 9564 1057 1012 1055 1012 12194 3343 1998 2506 18711 1997 7816 1997 19888 10085 3126 7389 9243 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:20:22 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "06/08/2021 22:20:23 - INFO - root -   tensor([[ 0.4612,  0.5725, -0.8174],\n",
      "        [ 0.6722, -0.0659, -0.6717],\n",
      "        [ 0.6417,  0.0708, -0.7478]])\n"
     ]
    }
   ],
   "source": [
    "result = predict(text,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:20.519047Z",
     "start_time": "2020-03-23T15:59:20.440450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>textblob_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcoin’s price has fallen to its lowest point in over a week as traders stare down prospects of shifting U.S. monetary policy and continued tightening of regulation of cryptocurrencies in China.</td>\n",
       "      <td>[0.41733512, 0.46646473, 0.11620015]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.049130</td>\n",
       "      <td>-0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other notable cryptos were also trading in the red, with the top 10 by market capitalization having fallen between 7.3% and 12.9% over the previous 24 hours.</td>\n",
       "      <td>[0.5750858, 0.27490568, 0.15000847]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.300180</td>\n",
       "      <td>0.141667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polkadot and XRP were the hardest hit, down 12.93% and 11.39%, respectively.</td>\n",
       "      <td>[0.5511973, 0.31143925, 0.13736351]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>-0.077778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                              sentence  \\\n",
       "0  Bitcoin’s price has fallen to its lowest point in over a week as traders stare down prospects of shifting U.S. monetary policy and continued tightening of regulation of cryptocurrencies in China.   \n",
       "1  Other notable cryptos were also trading in the red, with the top 10 by market capitalization having fallen between 7.3% and 12.9% over the previous 24 hours.                                         \n",
       "2  Polkadot and XRP were the hardest hit, down 12.93% and 11.39%, respectively.                                                                                                                          \n",
       "\n",
       "                                  logit prediction  sentiment_score  \\\n",
       "0  [0.41733512, 0.46646473, 0.11620015]  negative  -0.049130          \n",
       "1  [0.5750858, 0.27490568, 0.15000847]   positive   0.300180          \n",
       "2  [0.5511973, 0.31143925, 0.13736351]   positive   0.239758          \n",
       "\n",
       "   textblob_prediction  \n",
       "0 -0.155556             \n",
       "1  0.141667             \n",
       "2 -0.077778             "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "result['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:38.737969Z",
     "start_time": "2020-03-23T15:59:38.718255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment is 0.16.\n"
     ]
    }
   ],
   "source": [
    "print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:45.922058Z",
     "start_time": "2020-03-23T15:59:45.904622Z"
    }
   },
   "outputs": [],
   "source": [
    "text2 = \"Ether (ETH) eclipsed $4,000 for the first time on Monday, passing the \\\n",
    "psychologically significant barrier on multiple exchanges, including Coinbase. \\\n",
    "The new milestone comes just a week after breaking $3,000. The remarkable run has \\\n",
    "even prompted renewed speculation that there could be a “flippening” on the horizon \\\n",
    "— a long-anticipated event among the Ethereum community in which ETH overtakes \\\n",
    "Bitcoin (BTC) in market capitalization.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:48.152474Z",
     "start_time": "2020-03-23T15:59:47.028417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/08/2021 22:31:35 - INFO - finbert.utils -   *** Example ***\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   guid: 0\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   tokens: [CLS] ether ( et ##h ) eclipse ##d $ 4 , 000 for the first time on monday , passing the psychological ##ly significant barrier on multiple exchanges , including coin ##base . [SEP]\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   input_ids: 101 28855 1006 3802 2232 1007 13232 2094 1002 1018 1010 2199 2005 1996 2034 2051 2006 6928 1010 4458 1996 8317 2135 3278 8803 2006 3674 15800 1010 2164 9226 15058 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/08/2021 22:31:35 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "06/08/2021 22:31:35 - INFO - root -   tensor([[ 0.7912, -0.1505, -0.8027],\n",
      "        [ 0.6823, -0.4164, -0.9943],\n",
      "        [ 0.6142, -0.0141, -0.7391]])\n"
     ]
    }
   ],
   "source": [
    "result2 = predict(text2,model)\n",
    "blob = TextBlob(text2)\n",
    "result2['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:59:50.428951Z",
     "start_time": "2020-03-23T15:59:50.402385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>textblob_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ether (ETH) eclipsed $4,000 for the first time on Monday, passing the psychologically significant barrier on multiple exchanges, including Coinbase.</td>\n",
       "      <td>[0.6277018, 0.24478924, 0.12750891]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.382913</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new milestone comes just a week after breaking $3,000.</td>\n",
       "      <td>[0.65775746, 0.21923997, 0.12300254]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.438518</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The remarkable run has even prompted renewed speculation that there could be a “flippening” on the horizon — a long-anticipated event among the Ethereum community in which ETH overtakes Bitcoin (BTC) in market capitalization.</td>\n",
       "      <td>[0.5580745, 0.29772595, 0.1441996]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.260349</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                            sentence  \\\n",
       "0  Ether (ETH) eclipsed $4,000 for the first time on Monday, passing the psychologically significant barrier on multiple exchanges, including Coinbase.                                                                                \n",
       "1  The new milestone comes just a week after breaking $3,000.                                                                                                                                                                          \n",
       "2  The remarkable run has even prompted renewed speculation that there could be a “flippening” on the horizon — a long-anticipated event among the Ethereum community in which ETH overtakes Bitcoin (BTC) in market capitalization.   \n",
       "\n",
       "                                  logit prediction  sentiment_score  \\\n",
       "0  [0.6277018, 0.24478924, 0.12750891]   positive   0.382913          \n",
       "1  [0.65775746, 0.21923997, 0.12300254]  positive   0.438518          \n",
       "2  [0.5580745, 0.29772595, 0.1441996]    positive   0.260349          \n",
       "\n",
       "   textblob_prediction  \n",
       "0  0.208333             \n",
       "1  0.136364             \n",
       "2  0.750000             "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T16:00:27.031491Z",
     "start_time": "2020-03-23T16:00:27.012639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment is 0.36.\n"
     ]
    }
   ],
   "source": [
    "print(f'Average sentiment is %.2f.' % (result2.sentiment_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8956ef01",
   "metadata": {},
   "source": [
    "# XLNET Training\n",
    "This notebook demonstrates training and performance evaluation of the XLNET generalized autoregressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106935dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a676e",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "First, we load a labeled dataset of crypto-related social media comments and convert the sentiment labels ('positive', 'negative', 'neutral') to numbers (0, 1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa941c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       1000 non-null   object\n",
      " 1   sentiment  1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "                                                text  sentiment\n",
      "0   I have just encountered a Bitcoin scam on a d...          2\n",
      "1   Maybe theyll rename themselves once theyve am...          2\n",
      "2  - Part of NFT sale royalties will be swapped f...          2\n",
      "3  ' The requested withdrawal amount is lower tha...          2\n",
      "4   this clown still buying machine slave produce...          1\n",
      "5  \"Buy this, buy that\" is terrible advice. I see...          1\n",
      "6  \"Crypto Analyst says bitcoin will be $100k/$30...          0\n",
      "7         \"cute animal faces\" im looking at you Doge          0\n",
      "8  \"During that BTC run\" most altcoins will also ...          2\n",
      "9  \"In the end, it doesnt matter if you have a sc...          2\n"
     ]
    }
   ],
   "source": [
    "# Load labeled crypto sentiment data\n",
    "path_to_data = '../reddit/sentiment_labels_clean.csv'\n",
    "df = pd.read_csv(path_to_data)\n",
    "\n",
    "# clip data\n",
    "df = df[:1000]\n",
    "\n",
    "# Drop columns that are not used for training\n",
    "df = df.drop(['id', 'coin'], axis=1)\n",
    "\n",
    "# Function to convert labels to number.\n",
    "def sentiment2label(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return 0\n",
    "    elif sentiment == 'negative':\n",
    "        return 1\n",
    "    else: # neutral\n",
    "        return 2\n",
    "\n",
    "df['sentiment'] = df['sentiment'].apply(sentiment2label)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa123f",
   "metadata": {},
   "source": [
    "## XLNET Training\n",
    "Here, the XLNetSentimentTrain class is used to train the XLNET model on the cypto dataset.  The tuning hyperparameters are: batchsize, number of epochs, and text sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db78432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training class\n",
    "from xlnet import XLNetSentimentTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac65bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.917634402002607 Train accuracy 0.6428571428571429\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.9170379241307577 Val accuracy 0.6614583333333334\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 2/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.8351039460727147 Train accuracy 0.6629464285714286\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8619025746981303 Val accuracy 0.6614583333333334\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.8208545701844352 Train accuracy 0.6651785714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8539266586303711 Val accuracy 0.6614583333333334\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.7643675037792751 Train accuracy 0.6741071428571429\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8334299921989441 Val accuracy 0.6666666666666666\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 5/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.6525135806628636 Train accuracy 0.7522321428571429\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8342727820078532 Val accuracy 0.6822916666666666\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 6/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.5497046496186938 Train accuracy 0.7901785714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8564300338427225 Val accuracy 0.671875\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.47266622526305063 Train accuracy 0.796875\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.9134148955345154 Val accuracy 0.6614583333333334\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.3813729541642325 Train accuracy 0.8526785714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.8988794684410095 Val accuracy 0.6666666666666666\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.28481108375958036 Train accuracy 0.90625\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.9004579782485962 Val accuracy 0.6979166666666666\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 10/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.2498649720634733 Train accuracy 0.9151785714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 0.9706650177637736 Val accuracy 0.703125\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 11/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.21153852556432998 Train accuracy 0.9263392857142857\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.0156649351119995 Val accuracy 0.671875\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.13051870145968028 Train accuracy 0.9620535714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.1259562174479167 Val accuracy 0.6666666666666666\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.10822733757751328 Train accuracy 0.9709821428571429\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.2116345167160034 Val accuracy 0.6614583333333334\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.09724169171282224 Train accuracy 0.9732142857142857\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.2027907172838848 Val accuracy 0.71875\n",
      "\n",
      "Saving model ./models/xlnet_model_batch64.bin\n",
      "Epoch 15/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.07130507459597928 Train accuracy 0.9821428571428571\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.1697537104288738 Val accuracy 0.6927083333333334\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.03597319099519934 Train accuracy 0.9977678571428571\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.2845290501912434 Val accuracy 0.6927083333333334\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.033403865327792506 Train accuracy 0.9933035714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.3714547554651897 Val accuracy 0.6822916666666666\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.023514568539602414 Train accuracy 0.9977678571428571\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.4627148707707722 Val accuracy 0.6822916666666666\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.022062760245587145 Train accuracy 0.9933035714285714\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.48102863629659 Val accuracy 0.6875\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch 0/8\n",
      "train_epoch 1/8\n",
      "train_epoch 2/8\n",
      "train_epoch 3/8\n",
      "train_epoch 4/8\n",
      "train_epoch 5/8\n",
      "train_epoch 6/8\n",
      "train_epoch 7/8\n",
      "Filling partial batch (got 52, expected 64)\n",
      "Train loss 0.016141011512705257 Train accuracy 0.9955357142857143\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Val loss 1.510250449180603 Val accuracy 0.6822916666666666\n",
      "\n",
      "eval_model 0/4\n",
      "eval_model 1/4\n",
      "eval_model 2/4\n",
      "eval_model 3/4\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "Test Accuracy : 0.75\n",
      "Test Loss : 0.903520425160726\n",
      "Skipped partial batch (got 58, expected 64)\n",
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.8968266010284424 Train accuracy 0.6499999999999999\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.856189239025116 Val accuracy 0.6791666666666666\n",
      "\n",
      "Saving model ./models/xlnet_model_batch48.bin\n",
      "Epoch 2/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.8520925581455231 Train accuracy 0.6645833333333333\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8446443438529968 Val accuracy 0.6791666666666666\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.8044181406497956 Train accuracy 0.6666666666666666\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8507078528404236 Val accuracy 0.6458333333333334\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.7547434985637664 Train accuracy 0.7000000000000002\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8022772669792175 Val accuracy 0.675\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.633096182346344 Train accuracy 0.7333333333333334\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8126257061958313 Val accuracy 0.6708333333333334\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.5345043897628784 Train accuracy 0.7749999999999999\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.835065484046936 Val accuracy 0.65\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.37101230919361117 Train accuracy 0.8583333333333332\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8928706884384155 Val accuracy 0.6666666666666666\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.3242005780339241 Train accuracy 0.8875\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.8222104430198669 Val accuracy 0.6666666666666667\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.2686075881123543 Train accuracy 0.9\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.9214188098907471 Val accuracy 0.6916666666666667\n",
      "\n",
      "Saving model ./models/xlnet_model_batch48.bin\n",
      "Epoch 10/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.262631756067276 Train accuracy 0.8979166666666666\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 0.932205057144165 Val accuracy 0.6875\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.1536284454166889 Train accuracy 0.9499999999999998\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.017945945262909 Val accuracy 0.675\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.07803309503942728 Train accuracy 0.9770833333333334\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.1281521916389465 Val accuracy 0.6541666666666667\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.061226646043360235 Train accuracy 0.9874999999999998\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.3013680219650268 Val accuracy 0.6541666666666666\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.06608213502913714 Train accuracy 0.9770833333333332\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.3632604122161864 Val accuracy 0.6916666666666667\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.04423231482505798 Train accuracy 0.9833333333333332\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.3779504299163818 Val accuracy 0.6583333333333334\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.029669816978275775 Train accuracy 0.9875\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.5274266719818115 Val accuracy 0.6541666666666666\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.025860922131687402 Train accuracy 0.9916666666666666\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.4820111036300658 Val accuracy 0.6833333333333332\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.01624949073884636 Train accuracy 0.9979166666666668\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.547101378440857 Val accuracy 0.6541666666666667\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.014583066909108312 Train accuracy 0.9958333333333333\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.589410400390625 Val accuracy 0.675\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train_epoch 0/11\n",
      "train_epoch 1/11\n",
      "train_epoch 2/11\n",
      "train_epoch 3/11\n",
      "train_epoch 4/11\n",
      "train_epoch 5/11\n",
      "train_epoch 6/11\n",
      "train_epoch 7/11\n",
      "train_epoch 8/11\n",
      "train_epoch 9/11\n",
      "train_epoch 10/11\n",
      "Filling partial batch (got 20, expected 48)\n",
      "Train loss 0.017584975191857664 Train accuracy 0.9916666666666666\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Val loss 1.6274807453155518 Val accuracy 0.6541666666666667\n",
      "\n",
      "eval_model 0/6\n",
      "eval_model 1/6\n",
      "eval_model 2/6\n",
      "eval_model 3/6\n",
      "eval_model 4/6\n",
      "eval_model 5/6\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "Test Accuracy : 0.7583333333333333\n",
      "Test Loss : 0.7634737133979798\n",
      "Skipped partial batch (got 10, expected 48)\n",
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.8816971182823181 Train accuracy 0.6583333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.8573705894606454 Val accuracy 0.6741071428571429\n",
      "\n",
      "Saving model ./models/xlnet_model_batch32.bin\n",
      "Epoch 2/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.8447134256362915 Train accuracy 0.6645833333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.8417968494551522 Val accuracy 0.6741071428571429\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.7898467501004537 Train accuracy 0.68125\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.8360297509602138 Val accuracy 0.6696428571428571\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.6974042932192485 Train accuracy 0.7166666666666667\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.7931125334330967 Val accuracy 0.6651785714285714\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.5741395076115926 Train accuracy 0.7666666666666667\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.7471429279872349 Val accuracy 0.7410714285714286\n",
      "\n",
      "Saving model ./models/xlnet_model_batch32.bin\n",
      "Epoch 6/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.4155338724454244 Train accuracy 0.8458333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.8412076490265983 Val accuracy 0.6651785714285714\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.3003558953603109 Train accuracy 0.8958333333333334\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 0.8428097026688712 Val accuracy 0.6919642857142857\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.25323339104652404 Train accuracy 0.91875\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.1740086419241769 Val accuracy 0.5714285714285714\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.14392484029134114 Train accuracy 0.9583333333333334\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.1809179101671492 Val accuracy 0.5982142857142857\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.09533107342819373 Train accuracy 0.96875\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.4173683864729745 Val accuracy 0.5446428571428571\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.30042998467882476 Train accuracy 0.90625\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.2439443809645516 Val accuracy 0.7232142857142857\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.1736708824833234 Train accuracy 0.9416666666666667\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.1813435299055917 Val accuracy 0.7455357142857143\n",
      "\n",
      "Saving model ./models/xlnet_model_batch32.bin\n",
      "Epoch 13/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.05384789990882079 Train accuracy 0.9833333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.1436094556535994 Val accuracy 0.7366071428571429\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.024974830246840916 Train accuracy 0.9958333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.2815738916397095 Val accuracy 0.7366071428571429\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.013907990550311904 Train accuracy 0.9958333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.3374339512416296 Val accuracy 0.7276785714285714\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.008847470558248461 Train accuracy 0.9958333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.4607709901673454 Val accuracy 0.7232142857142857\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.015571761775451403 Train accuracy 0.9916666666666667\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.4391999414988927 Val accuracy 0.7142857142857143\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.008026859862729907 Train accuracy 0.9979166666666667\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.452220814568656 Val accuracy 0.71875\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.013113374429910134 Train accuracy 0.9958333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.4950281892504012 Val accuracy 0.71875\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train_epoch 0/16\n",
      "train_epoch 1/16\n",
      "train_epoch 2/16\n",
      "train_epoch 3/16\n",
      "train_epoch 4/16\n",
      "train_epoch 5/16\n",
      "train_epoch 6/16\n",
      "train_epoch 7/16\n",
      "train_epoch 8/16\n",
      "train_epoch 9/16\n",
      "train_epoch 10/16\n",
      "train_epoch 11/16\n",
      "train_epoch 12/16\n",
      "train_epoch 13/16\n",
      "train_epoch 14/16\n",
      "train_epoch 15/16\n",
      "Filling partial batch (got 20, expected 32)\n",
      "Train loss 0.01110511008882895 Train accuracy 0.9958333333333333\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Val loss 1.492025417940957 Val accuracy 0.7232142857142857\n",
      "\n",
      "eval_model 0/8\n",
      "eval_model 1/8\n",
      "eval_model 2/8\n",
      "eval_model 3/8\n",
      "eval_model 4/8\n",
      "eval_model 5/8\n",
      "eval_model 6/8\n",
      "eval_model 7/8\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "Test Accuracy : 0.7098214285714286\n",
      "Test Loss : 1.1479890857424055\n",
      "Skipped partial batch (got 26, expected 32)\n",
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.8938404994626199 Train accuracy 0.6633064516129032\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 0.8460714101791382 Val accuracy 0.6791666666666667\n",
      "\n",
      "Saving model ./models/xlnet_model_batch16.bin\n",
      "Epoch 2/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.8042101052499586 Train accuracy 0.6774193548387096\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 0.7791820009549458 Val accuracy 0.7\n",
      "\n",
      "Saving model ./models/xlnet_model_batch16.bin\n",
      "Epoch 3/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.7012144259868129 Train accuracy 0.717741935483871\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 0.715756227572759 Val accuracy 0.725\n",
      "\n",
      "Saving model ./models/xlnet_model_batch16.bin\n",
      "Epoch 4/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.47895676762826983 Train accuracy 0.8185483870967742\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 0.7493897338708242 Val accuracy 0.7125\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.31292824663462177 Train accuracy 0.8911290322580645\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 0.8739579081535339 Val accuracy 0.7\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.13734169764023635 Train accuracy 0.9536290322580645\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 1.7859440247217815 Val accuracy 0.5583333333333333\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.14838671761624997 Train accuracy 0.9455645161290323\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 1.8318822264671326 Val accuracy 0.5833333333333334\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.10746994572541406 Train accuracy 0.969758064516129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 1.5262705047925313 Val accuracy 0.6666666666666666\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.020048534125840713 Train accuracy 0.9959677419354839\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.0657659570376077 Val accuracy 0.6666666666666666\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.011452283261948446 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.276127811272939 Val accuracy 0.6625\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.048286175615841434 Train accuracy 0.9858870967741935\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.453390061855316 Val accuracy 0.6458333333333334\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.03241064118018614 Train accuracy 0.9919354838709677\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.0058837890625 Val accuracy 0.7083333333333334\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.01017236784278911 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.004142439365387 Val accuracy 0.7125\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.00841291128275653 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 1.9888202865918478 Val accuracy 0.6916666666666667\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.006630533155159003 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.0429817914962767 Val accuracy 0.7208333333333333\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.007238202721055131 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.0144939760367078 Val accuracy 0.7041666666666667\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.00802314881894422 Train accuracy 0.9959677419354839\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 1.999800024429957 Val accuracy 0.7083333333333334\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.006784489247600563 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.031794786453247 Val accuracy 0.7083333333333334\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.0051566144348696745 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.058479078610738 Val accuracy 0.7125\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train_epoch 0/32\n",
      "train_epoch 1/32\n",
      "train_epoch 2/32\n",
      "train_epoch 3/32\n",
      "train_epoch 4/32\n",
      "train_epoch 5/32\n",
      "train_epoch 6/32\n",
      "train_epoch 7/32\n",
      "train_epoch 8/32\n",
      "train_epoch 9/32\n",
      "train_epoch 10/32\n",
      "train_epoch 11/32\n",
      "train_epoch 12/32\n",
      "train_epoch 13/32\n",
      "train_epoch 14/32\n",
      "train_epoch 15/32\n",
      "train_epoch 16/32\n",
      "train_epoch 17/32\n",
      "train_epoch 18/32\n",
      "train_epoch 19/32\n",
      "train_epoch 20/32\n",
      "train_epoch 21/32\n",
      "train_epoch 22/32\n",
      "train_epoch 23/32\n",
      "train_epoch 24/32\n",
      "train_epoch 25/32\n",
      "train_epoch 26/32\n",
      "train_epoch 27/32\n",
      "train_epoch 28/32\n",
      "train_epoch 29/32\n",
      "train_epoch 30/32\n",
      "train_epoch 31/32\n",
      "Filling partial batch (got 4, expected 16)\n",
      "Train loss 0.00543468261093949 Train accuracy 0.9979838709677419\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Val loss 2.0638737440109254 Val accuracy 0.7083333333333334\n",
      "\n",
      "eval_model 0/16\n",
      "eval_model 1/16\n",
      "eval_model 2/16\n",
      "eval_model 3/16\n",
      "eval_model 4/16\n",
      "eval_model 5/16\n",
      "eval_model 6/16\n",
      "eval_model 7/16\n",
      "eval_model 8/16\n",
      "eval_model 9/16\n",
      "eval_model 10/16\n",
      "eval_model 11/16\n",
      "eval_model 12/16\n",
      "eval_model 13/16\n",
      "eval_model 14/16\n",
      "eval_model 15/16\n",
      "Skipped partial batch (got 10, expected 16)\n",
      "Test Accuracy : 0.75\n",
      "Test Loss : 0.626006156206131\n",
      "Skipped partial batch (got 10, expected 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrmorris/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rrmorris/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rrmorris/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Some tuning advice available at:\n",
    "# https://mccormickml.com/2019/09/19/XLNet-fine-tuning/\n",
    "#\n",
    "# Run training on the labeled crypto data - find the best batch size\n",
    "# Todo: Batchsize of 128 is also recommended, but don't have enough GPU memory\n",
    "batches=[64, 48, 32, 16]\n",
    "history = []\n",
    "for batchsize in batches:\n",
    "    xlnet_train = XLNetSentimentTrain(batchsize=batchsize, max_len=64)\n",
    "    history.append(xlnet_train.train(df, ['text', 'sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561b6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20\n",
      "Batchsize: 64\n",
      "Max len: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.61      0.44      0.51        43\n",
      "    negative       0.50      0.42      0.46        19\n",
      "     neutral       0.81      0.90      0.85       130\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.64      0.59      0.61       192\n",
      "weighted avg       0.73      0.75      0.74       192\n",
      "\n",
      "\n",
      "Epochs: 20\n",
      "Batchsize: 48\n",
      "Max len: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.76      0.45      0.57        55\n",
      "    negative       0.40      0.27      0.32        22\n",
      "     neutral       0.79      0.93      0.85       163\n",
      "\n",
      "    accuracy                           0.76       240\n",
      "   macro avg       0.65      0.55      0.58       240\n",
      "weighted avg       0.74      0.76      0.74       240\n",
      "\n",
      "\n",
      "Epochs: 20\n",
      "Batchsize: 32\n",
      "Max len: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.70      0.28      0.40        50\n",
      "    negative       0.35      0.36      0.36        22\n",
      "     neutral       0.76      0.90      0.82       152\n",
      "\n",
      "    accuracy                           0.71       224\n",
      "   macro avg       0.60      0.51      0.53       224\n",
      "weighted avg       0.70      0.71      0.68       224\n",
      "\n",
      "\n",
      "Epochs: 20\n",
      "Batchsize: 16\n",
      "Max len: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.81      0.38      0.52        55\n",
      "    negative       0.00      0.00      0.00        22\n",
      "     neutral       0.74      0.98      0.84       163\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.52      0.45      0.45       240\n",
      "weighted avg       0.69      0.75      0.69       240\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hist in history:\n",
    "    print('Epochs: {}'.format(hist['epochs']))\n",
    "    print('Batchsize: {}'.format(hist['batchsize']))\n",
    "    print('Max len: {}'.format(hist['max_len']))\n",
    "    print(hist['classification_report'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82ea2f",
   "metadata": {},
   "source": [
    "## Batch Size Selection\n",
    "Batchsize=64, 48 and 16 have the best overall accuracy (>= 75) but batchsize=48 has best balance of precision and recall scores. We will use batchsize=48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d19b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = history[1]\n",
    "# Plot of training and value accuracy\n",
    "plt.plot(best['train_acc'])\n",
    "plt.plot(best['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'value'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Training accuracy starts to level off after about 11 epochs and the best value accuracy is found at 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4156f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqTklEQVR4nO3deXxcZb3H8c8vk0nS7E03StMVCjSU0kJawEJBAdmkFVBkl/26gIpcFUUFuXpFULyieBEVZBPKRYQiS1mlFCk0LQW6QulCU7qvadPsv/vHnODQJu20zeRkZr7v12teOXPOM5nfTCfz7XnOOc9j7o6IiGSurLALEBGRcCkIREQynIJARCTDKQhERDKcgkBEJMMpCEREMpyCQDKWmT1jZl/u6LYiqcZ0HYGkEjPbEnc3H6gHmoP7/+HuD3Z+VXvOzI4DHnD38pBLkQyWHXYBIrvD3Qtbl81sCXC5u7+wfTszy3b3ps6sTSRVqWtI0oKZHWdm1Wb2PTNbCdxjZt3N7B9mtsbMNgTL5XGP+aeZXR4sX2xmU83sl0HbxWZ2yh62HWxmU8ysxsxeMLM7zOyBPXhNw4Ln3Whmc8xsfNy2U81sbvAcy83sP4P1PYPXudHM1pvZq2amv3PZKX1AJJ3sA5QBA4EriX2+7wnuDwC2Ab/byeOPABYAPYFbgD+bme1B278CbwI9gBuBC3f3hZhZFHgSeA7oDVwNPGhmBwZN/kysK6wIGA68FKy/FqgGegF9gB8A6v+VnVIQSDppAW5w93p33+bu69z9b+5e6+41wM+AY3fy+KXu/kd3bwbuBfoS+zJNuK2ZDQBGAz929wZ3nwpM2oPXciRQCNwc/J6XgH8A5wbbG4EKMyt29w3uPjNufV9goLs3uvurrgOBsgsKAkkna9y9rvWOmeWb2R/MbKmZbQamAKVmFmnn8StbF9y9Nlgs3M22+wLr49YBLNvN10Hwe5a5e0vcuqVAv2D5LOBUYKmZvWJmRwXrbwUWAs+Z2SIzu24PnlsyjIJA0sn2//O9FjgQOMLdi4Fxwfr2uns6wgqgzMzy49b134Pf8xHQf7v+/QHAcgB3n+7uE4h1Gz0OPBKsr3H3a919CDAe+LaZHb8Hzy8ZREEg6ayI2HGBjWZWBtyQ7Cd096VAFXCjmeUE/1M/fVePM7O8+BuxYwy1wHfNLBqcZno68HDwe883sxJ3bwQ2E+sWw8w+Z2b7B8crNhE7tbalrecUaaUgkHT2P0A3YC0wDXi2k573fOAoYB3wU2Aisesd2tOPWGDF3/oT++I/hVj9vwcucvf5wWMuBJYEXV5fCZ4TYCjwArAFeB34vbu/3GGvTNKSLigTSTIzmwjMd/ek75GI7AntEYh0MDMbbWb7mVmWmZ0MTCDWjy/SJenKYpGOtw/wGLHrCKqBr7r7W+GWJNI+dQ2JiGQ4dQ2JiGS4lOsa6tmzpw8aNCjsMkREUsqMGTPWunuvtralXBAMGjSIqqqqsMsQEUkpZra0vW3qGhIRyXAKAhGRDKcgEBHJcCl3jKAtjY2NVFdXU1dXt+vGKSQvL4/y8nKi0WjYpYhIGkuLIKiurqaoqIhBgwbR/jwiqcXdWbduHdXV1QwePDjsckQkjaVF11BdXR09evRImxAAMDN69OiRdns5ItL1pEUQAGkVAq3S8TWJSNeTNkGwK3WNzazcVEdLi4bUEBGJlzFBUFPXyOqaOt5fXUNNXWOH//7CwvZmNBQR6doyJgh6FeUxpGcBAIvXbmXZ+lqamjVxk4hIxgQBQGFelKG9i+hdlMfGbY0sWFXD+q0NdOQIrO7Od77zHYYPH84hhxzCxIkTAVixYgXjxo1j5MiRDB8+nFdffZXm5mYuvvjij9v++te/7rA6REQSlRanj8b7yZNzmPvR5l22a3GnoamF5hYnkmXkZGeR1c7B2Yp9i7nh9IMTev7HHnuMWbNm8fbbb7N27VpGjx7NuHHj+Otf/8pJJ53E9ddfT3NzM7W1tcyaNYvly5cze/ZsADZu3Jjw6xQR6SgZtUcQL8uMvGiE3GgWLe5sa2ymoQO6iqZOncq5555LJBKhT58+HHvssUyfPp3Ro0dzzz33cOONN/Luu+9SVFTEkCFDWLRoEVdffTXPPvssxcXFHfDKRER2T9rtEST6P/d4jc0trNxUx4baBnKzI/QrzaMwr2Ov5h03bhxTpkzhqaee4uKLL+bb3/42F110EW+//TaTJ0/mzjvv5JFHHuHuu+/u0OcVEdmVjN0jiBeNZNG/LJ/BPQtwnEV7cTD5mGOOYeLEiTQ3N7NmzRqmTJnCmDFjWLp0KX369OGKK67g8ssvZ+bMmaxdu5aWlhbOOussfvrTnzJz5swkvDoRkZ1Luz2CvVGUF+WA3tmsrqlnzZZ6Ntc10rekG93zowlf3HXGGWfw+uuvc+ihh2Jm3HLLLeyzzz7ce++93HrrrUSjUQoLC7nvvvtYvnw5l1xyCS0tscD5+c9/nsyXJyLSppSbs7iystK3n5hm3rx5DBs2rEOfp66xmeUbtrG1oYmC3Gz6lXYjLxrp0OdIRDJem4hkHjOb4e6VbW1T11A78qIRhvQqoLx7N+oam3l/9RZWba6jJcWCU0RkV9Q1tBNmRllBLkV5UVZsrGPV5jo2bWukf/dudMvRWyci6SFt9giS2cUVjWQxoEc+g3oU0NziLFy9NTZuUZL3DlKt205EUlNaBEFeXh7r1q1L+hdncbcoQ3sXUpofZXVNHQtXb2FbQ1NSnqt1PoK8vLyk/H4RkVZp0b9RXl5OdXU1a9as6bTnbG5sprq2kQ8/cIrysinKy+7wYaNbZygTEUmmtAiCaDQayixem2ob+ck/5vDYzGUctE8Rv/zioQzvV9LpdYiI7I206BoKS0l+lNvOHsmfLqpk/dYGJtzxGr96bgENTRrVVERSh4KgA5xQ0YfnrzmWCSP35bcvLWT876Yye/mmsMsSEUmIgqCDaO9ARFKVgqCDae9ARFJNUoPAzE42swVmttDMrmtj+wAze9nM3jKzd8zs1GTW01m0dyAiqSRpQWBmEeAO4BSgAjjXzCq2a/ZD4BF3HwWcA/w+WfWEoa29g0QmzRER6UzJ3CMYAyx090Xu3gA8DEzYro0DrbOxlAAfJbGeUMTvHazd0sCEO6Zy5ysf0Nyiq4ZFpGtIZhD0A5bF3a8O1sW7EbjAzKqBp4Gr2/pFZnalmVWZWVVnXjTWkU6o6MNz14zjMwf15uZn5nPuXdNYtr427LJEREI/WHwu8Bd3LwdOBe43sx1qcve73L3S3St79erV6UV2lLKCHO684HB++cVDmbtiM6f85lX+r2qZxhQSkVAlMwiWA/3j7pcH6+JdBjwC4O6vA3lAzyTWFDoz4wuHl/PMN4+hYt9ivvPoO3zlgRms21IfdmkikqGSGQTTgaFmNtjMcogdDJ60XZsPgeMBzGwYsSBIzb6f3dS/LJ+HrjiSH5x6EC/PX8NJ//MqL81fFXZZIpKBkhYE7t4EXAVMBuYROztojpndZGbjg2bXAleY2dvAQ8DFnkH9JJEs48px+/HEVWPpWZjDpX+p4vuPvcvW+uSMaCoi0pa0mKoyHdQ3NXPbc+9x16uLGFCWz21nj+Twgd3DLktE0oSmqkwBudkRvn/qMB6+4kiamp0v3vkvfvXcAhqbdRGaiCSXgqCLOWJID5791jGceVg5v31pIWf+/l8sXF0TdlkiksYUBF1QUV6UX37xUO684DCqN9Ry2u1Tuee1xbToIjQRSQIFQRd28vC+TL5mHJ/arwc/eXIuF/9lOvVNzWGXJSJpRkHQxfUuyuPui0dz4+kVTHlvDXdPXRJ2SSKSZhQEKcDMuHjsYE6s6MNvX3qflZvqwi5JRNKIgiCF/Oi0CppanJufmRd2KSKSRhQEKWRAj3z+Y9wQHp/1EdOXrA+7HBFJEwqCFPO14/Zn35I8bnhijoayFpEOoSBIMd1yIvzgtGHMXbGZh978MOxyRCQNKAhS0GmH9OXIIWX88rkFbKxtCLscEUlxCoIUZGbcOP5gauqa+NVz74VdjoikOAVBijpon2IuPHIgD76xVPMgi8heURCksGtOOICSblFunDRHs5yJyB5TEKSwkvwo3znpIN5csp4n31kRdjkikqIUBCnuS6P7M7xfMf/91DxNaCMie0RBkOIiWcZPxh/Mys11/P6fC8MuR0RSkIIgDRw+sIwzR/Xjj1MWs2Tt1rDLEZEUoyBIE9edchDRiPHTp+aGXYqIpBgFQZroXZzHN44fygvzVvPygtVhlyMiKURBkEYuGTuYIT0LuOnJuTQ0aa5jEUmMgiCN5GRn8ePTK1i8dit3v7Y47HJEJEUoCNLMcQf25oRhvfnti++zarMmsBGRXVMQpKEfnlZBY7Nz8zPzwy5FRFKAgiANDepZwBXjBvP3t5ZTpQlsRGQXFARp6mvH7c8+xXncMEkT2IjIzikI0lRBbjY/OG0Ycz7azMTpy8IuR0S6MAVBGjt9RF/GDC7j1snzNYGNiLRLQZDGzIwbTz+YTdsa+fXzmsBGRNqmIEhzFfsWc/4RA7l/2lLmrdAENiKyIwVBBrj2swdQrAlsRKQdCoIMUJqfw3dOOpA3Fq/n/mlLwy5HRLoYBUGGOG/MAI47sBc/fWqeuohE5BMUBBnCzPjlFw+lOC/KNx56i20NzWGXJCJdhIIgg/QszOW2sw/l/dVb+C/NWyAiAQVBhhl3QC/+Y9wQ/vrGhzw7WxPei0iSg8DMTjazBWa20Myua6fN2WY218zmmNlfk1mPxFz72QMZUV7Cdx99h+Ubt4VdjoiELGlBYGYR4A7gFKACONfMKrZrMxT4PjDW3Q8GvpWseuTfcrKzuP2cUTS3ONc8PEtjEYlkuGTuEYwBFrr7IndvAB4GJmzX5grgDnffAODummOxkwzqWcB/fX44by5Zz+9eWhh2OSISomQGQT8gfrSz6mBdvAOAA8zsNTObZmYnt/WLzOxKM6sys6o1a9YkqdzMc+Zh5Zwxqh+/efE9pmu4apGMFfbB4mxgKHAccC7wRzMr3b6Ru9/l7pXuXtmrV6/OrTDN3TThYMq75/Oth2exqbYx7HJEJATJDILlQP+4++XBunjVwCR3b3T3xcB7xIJBOklRXpTbzx3Fqs11XPfYOxqCQiQDJTMIpgNDzWywmeUA5wCTtmvzOLG9AcysJ7GuokVJrEnaMLJ/Kf950oE8M3slD2vuApGMk7QgcPcm4CpgMjAPeMTd55jZTWY2Pmg2GVhnZnOBl4HvuPu6ZNUk7bvymCEcvX9PfvLkHBaurgm7HBHpRJZqXQGVlZVeVVUVdhlpafXmOk7+zav0Lsrl8a+PJS8aCbskEekgZjbD3Svb2hb2wWLpQnoX5/HLL45g/soabn5mftjliEgnURDIJ3zmoD5cMnYQf/nXEl6YuyrsckSkEygIZAfXnXIQFX2L+c6jb7Nqc13Y5YhIkikIZAe52RFuP3cUdY0tXDNRQ1CIpDsFgbRp/96F3Di+gn99sI4/TPkg7HJEJIkUBNKusyv7c9qIvvzqufd468MNYZcjIkmSUBCY2WNmdpqZKTgyiJnx32ccwj7FeXzj4bfYXKchKETSUaJf7L8HzgPeN7ObzezAJNYkXUhJtyi3nzuSjzbW8aPHZ2sICpE0lFAQuPsL7n4+cBiwBHjBzP5lZpeYWTSZBUr4Dh9Yxjc+M5QnZn3E9CXqIhJJNwl39ZhZD+Bi4HLgLeA3xILh+aRUJl3KleOGUJof5Z7XFoddioh0sESPEfwdeBXIB0539/HuPtHdrwYKk1mgdA3dciKcN2YAk+esZNn62rDLEZEOlOgewe3uXuHuP3f3T8x43t7YFZJ+LjxqIFlm3Pf6krBLEZEOlGgQVMRPGGNm3c3sa8kpSbqqviXdOPWQvjw8fRlb6pvCLkdEOkiiQXCFu29svRPMMXxFUiqSLu3SowdTU9fE32ZUh12KiHSQRIMgYmbWesfMIkBOckqSrmxk/1IOG1DKPa8tpkVDT4ikhUSD4Flgopkdb2bHAw8F6yQDXXr0YJasq+XlBavDLkVEOkCiQfA9YjOIfTW4vQh8N1lFSdd28sH7sG9JHnfrVFKRtJDoBWUt7v6/7v6F4PYHd29OdnHSNWVHsrjoU4N4beE65q/cHHY5IrKXEr2OYKiZPWpmc81sUest2cVJ13XO6P7kRbO4Z+qSsEsRkb2UaNfQPcD/Ak3Ap4H7gAeSVZR0faX5OZx1WDl/n7WcdVvqwy5HRPZCokHQzd1fJDbZ/VJ3vxE4LXllSSq4ZOwgGppa+OsbH4ZdiojshUSDoD4Ygvp9M7vKzM5AQ0tkvP17F3HsAb24b9pSGppawi5HRPZQokHwTWLjDH0DOBy4APhysoqS1HHp0YNZU1PPU+9+FHYpIrKHdhkEwcVjX3L3Le5e7e6XuPtZ7j6tE+qTLm7c0J7s37uQP09drLkKRFLULoMgOE306E6oRVKQmXHJ2EHMXr6ZqqWaq0AkFSXaNfSWmU0yswvN7MzWW1Irk5Rx5qhySrpFuXuqLjATSUXZCbbLA9YBn4lb58BjHV6RpJxuORHOO2IAf3jlA5atr6V/WX7YJYnIbkgoCNz9kmQXIqntoqMGcteURdz3+hKuP60i7HJEZDckFARmdg+xPYBPcPdLO7wiSUnxcxV884QDKMxNdGdTRMKW6DGCfwBPBbcXgWJgS7KKktR06dhBmqtAJAUl2jX0t/j7ZvYQMDUpFUnKGjWgO6MGlPKXfy3hwiMHkpVlu36QiIQu0T2C7Q0FendkIZIeLh07mMVrt/LP9zRXgUiqSHT00Roz29x6A54kNkeByCecPHwf+pbkcbdGJRVJGYnOR1Dk7sVxtwO27y4SAYhGsrjoqEFMXbiWBStrwi5HRBKQ6B7BGWZWEne/1Mw+n7SqJKWdOyaYq0AzmImkhESPEdzg7pta77j7RuCGXT3IzE42swVmttDMrttJu7PMzM2sMsF6pAtrnavgsbc0V4FIKkg0CNpqt9MzjoLB6u4ATgEqgHPNbIcrjcysiNjopm8kWIukgNa5Ch56U3MViHR1iQZBlZndZmb7BbfbgBm7eMwYYKG7L3L3BuBhYEIb7f4L+AVQl3DV0uV9PFfB65qrQKSrSzQIrgYagInEvtDrgK/v4jH9gGVx96uDdR8zs8OA/u7+VIJ1SAq59OjBrK6p5+l3V4RdiojsRKIXlG0F2u3j3xPBjGe3ARcn0PZK4EqAAQMGdGQZkkStcxXc/dpiJozcFzNdYCbSFSV61tDzZlYad7+7mU3excOWA/3j7pcH61oVAcOBf5rZEuBIYFJbB4zd/S53r3T3yl69eiVSsnQBrXMVvFO9iRmaq0Cky0q0a6hncKYQAO6+gV1fWTwdGGpmg80sBzgHmBT3Oza5e093H+Tug4BpwHh3r9qdFyBd28dzFehUUpEuK9EgaDGzj/tkzGwQbYxGGs/dm4CrgMnAPOARd59jZjeZ2fg9rFdSTOtcBc/OXkn1htqwyxGRNiQaBNcDU83sfjN7AHgF+P6uHuTuTwdXIe/n7j8L1v3Y3Se10fY47Q2kp4uOGoiZcd/rS8MuRUTakOgQE88ClcAC4CHgWmBbEuuSNNI6V8FDb37IwtUavVykq0n0YPHlxOYhuBb4T+B+4MbklSXp5uuf3o9IlnHq7a9yx8sLaWrWtQUiXUWiXUPfBEYDS93908AoYGOyipL0c9A+xTx/zbGcMKw3t05ewOd//xpzP9ocdlkiQuJBUOfudQBmluvu84EDk1eWpKNeRbn8/vzD+d/zD2PlpjrG/24qtz23gPqm5rBLE8loiQZBdXAdwePA82b2BKAjf7JHTjmkL89fcyzjD92X219ayOm/ncqsZRvDLkskY5n7Ts8C3fEBZscCJcCzwRhCnaqystKrqnRyUbp4ef5qfvD3d1m1uY7LjxnCt088gLxoJOyyRNKOmc1w9zZHeN7tqSrd/RV3nxRGCEj6+fRBvZl8zTi+NHoAd01ZxCm/eZU3F68PuyyRjLKncxaLdJjivCg/P/MQ/nr5ETS1tHD2H17nx0/MZkt9U9iliWQEBYF0GZ/avyeTvzWOS8YO4v5pSznp11N49f01YZclkvYUBNKl5Odkc8PpB/PoV44iN5rFhX9+k+8++jabtjWGXZpI2lIQSJd0+MAynv7GMXz1uP3428zlnHjbKzw/d1XYZYmkJQWBdFl50QjfO/kgHv/aWMoKcrjivipueGK2ZjwT6WAKAunyDikvYdJVR3P50YO59/WlnHPX66zYpKGuRDqKgkBSQk52Fj/8XAW/O28U81fW8Lnbp/KvD9aGXZZIWlAQSEr53Ih9mXTVWErzo1zwpze485UP2N2LIkXkkxQEknL2713EE1cdzSnD+3LzM/P5ygMz2Fyns4pE9pSCQFJSYW42vztvFD88bRgvzFvNhN+9xoKVNWGXJZKSFASSssyMy48ZwkNXHMmW+iY+f8drPDFredhliaQcBYGkvDGDy3jq6qM5pF8J33x4lk4xFdlNCgJJC72L83jwiiO4TKeYiuw2BYGkjWgkix99roI7zjuMBTrFVCRhCgJJO6eN6MsTV42le0GOTjEVSYCCQNLS/r2LePzrY3WKqUgCssMuQCRZWk8xHTW1lJ8/M59T/udVRvYvpawgh7KCHHoW5lBWkEuPwhx6BOtK83OIZFnYpYt0KgWBpLXWU0xHlJfymxffY/7Kzazf2sCG2rb3DrIMuufn0KMwFgw9gqAoK8hhUI8CTj90XwWFpB0FgWSEMYPLePDyIz++39TcwobaRtZvbWDdlnrWBT/Xb20IlhtYv7WBeUFwbAyCY8WmOr563H5hvQyRpFAQSEbKjmTRqyiXXkW5QNEu2zc2t/CNh97i1y+8x4kVfdi/d2HyixTpJDpYLJKAaCSLn0w4mPycCN999G2aW3QWkqQPBYFIgnoX5XHD6RXM/HAj9/5rSdjliHQYBYHIbvj8yH585qDe3DJ5PkvXbQ27HJEOoSAQ2Q1mxs/OGE40K4vr/vYuLeoikjSgIBDZTX1LunH9acN4fdE6Hpr+YdjliOw1BYHIHvjS6P6M3b8HP396Ph9t1OB2ktoUBCJ7wMy4+cwRtLjzg7+/q7GMJKUpCET2UP+yfL538kH8c8EaHpupCXEkdSkIRPbChUcOZPSg7vzkyTms3lwXdjkieySpQWBmJ5vZAjNbaGbXtbH922Y218zeMbMXzWxgMusR6WhZWcYvzhpBfVMLP3x8trqIJCUlLQjMLALcAZwCVADnmlnFds3eAirdfQTwKHBLsuoRSZYhvQr59okH8NzcVTz17oqwyxHZbcncIxgDLHT3Re7eADwMTIhv4O4vu3ttcHcaUJ7EekSS5rKjB3NoeQk3PDGHdVvqwy5HZLckMwj6Acvi7lcH69pzGfBMWxvM7EozqzKzqjVr1nRgiSIdIzuSxS1fOJTNdY385Mm5YZcjslu6xMFiM7sAqARubWu7u9/l7pXuXtmrV6/OLU4kQQfuU8TVnxnKpLc/4rk5K8MuRyRhyQyC5UD/uPvlwbpPMLMTgOuB8e6ufWpJaV89bj+G9S3mh4/PZtM2TY0pqSGZQTAdGGpmg80sBzgHmBTfwMxGAX8gFgKrk1iLSKeIRrK49QsjWLe1gZ89pS4iSQ1JCwJ3bwKuAiYD84BH3H2Omd1kZuODZrcChcD/mdksM5vUzq8TSRnD+5XwlWOH8EhVNVPe0zEt6fos1c57rqys9KqqqrDLENmpusZmPvfbqWxraGbyNeMozNVkgBIuM5vh7pVtbesSB4tF0k1eNMItXxjBR5u28Ytn5oddjshOKQhEkuSwAd25bOxg7p+2lGmL1oVdjki7FAQiSXTtZw9kYI98vve3d9jW0Bx2OSJtUhCIJFG3nAi/OGsES9fV8qvnFoRdjkibFAQiSXbkkB5ceORA/vzaYl6avyrsckR2oCAQ6QTXnXIQw/ct4asPzOT1D3S8QLoWBYFIJyjIzebeS8cwoCyfy++dzqxlG8MuSeRjCgKRTlJWkMMDlx9Bz6Jcvnz3m8xfuTnskkQABYFIp+pTnMcDlx1Bt2iEC/70JovWbAm7JBEFgUhn61+WzwOXH4G7c8Gf3mD5xm1hlyQZTkEgEoL9exdy32VjqKlv4vw/TmN1jeY7lvAoCERCcvC+JfzlkjGsrqnnoj+/ycbahrBLkgylIBAJ0eEDu/PHiypZtGYrX75nOlvqm8IuSTKQgkAkZGP378kd5x/G7OWbuPze6dQ1aigK6VwKApEu4MSKPtx29qG8sXg9X31gBg1NLWGXJBlEQSDSRUwY2Y+fff4QXl6whmsmzqK5JbXmCpHUpdkyRLqQ844YwNb6Jn729DzygwHrsrIs7LIkzSkIRLqYK8YNoaa+idtffJ+C3GxuOL0CM4WBJI+CQKQLuuaEoWypa+Lu1xZTnJfNtz97YNglSRpTEIh0QWbGjz43jK31Tdz+0kIKcrP5j2P3C7ssSVMKApEuysz47zMPYUtDEz9/Zj4FudlccOTAsMuSNKQgEOnCIlnGr88eybaGZn74+GzueW0xoweVUTmojDGDyuhf1k3HD2SvmXtqnaJWWVnpVVVVYZch0qnqGpu57/UlTFu0nqol69lcF7sCuXdRbhAM3Rk9qIxhfYuJ6CwjaYOZzXD3yja3KQhEUktLi/P+6i1MX7Ke6UvWU7Vkw8cjmBbmZjNqQOnH4TCqf3e65UR2+znqGpvZtK2RjbWNwc8G6ppaOGxAKeXd8zv6JUknUBCIpLnlG7dRFYTC9CXrWbCqBnfIzjKG9yth9KDujCgvpbnFP/EFH7s17LCufidXNlf0LeaEij6cOKwPw/sVq2sqRSgIRDLMptpGZn644eM9hlnVG3cYtqIgJ0Jpfg7F3aKUdotSEtxK86MUxy2XdItS2i0HM3ht4VpemLeKGUs30OKwT3EeJ1T05oRhfThqvx7kZu/+3od0DgWBSIarb2pm4eot5EUjlHaLfdFHI3s+wsy6LfW8vGANL8xdxZT311Db0ExBToRxB/TixIo+fPrA3nQvyOnAVyB7S0EgIklT19jM6x+s4/l5q3hh7ipW19STZVA5qIwTh/XhxIo+DOpZEHaZGU9BICKdoqXFeXf5Jl6Yt4rn565i/soaIDYj2/HDejN6YBkjykvoXZwXcqWZR0EgIqFYtr6WF+et4vl5q3hj0XqaghFV+xTncki/UkaUl3BIeQkj+pXQozA35GrTm4JAREJX29DEvBWbeXvZJt5dvol3qjeyaO1WWr+C+pV2iwuGUg7pV0JJfjTcotPIzoJAVxaLSKfIz8nm8IFlHD6w7ON1NXWNzPloM+9Wb+KdIByemb3y4+0De+RzSL8SRpSXMHzfEnoW5VKQm01hcNPFcx1DQSAioSnKi3LkkB4cOaTHx+s21TbG9hiWb+Td6k289eFG/vHOijYf3y0aoTDv38FQmJtNQW42RXmfXC7IiVCUF2Xf0m4M6JHPPsV5CpE4CgIR6VJK8qMcPbQnRw/t+fG6dVvqmbeiho3bGtha30RNXRNb6pvYWh/7WVP37+XlG7expb6RLUGbxuYdu79zIlmUd4+FwoCyuFtwPz8ns74aM+vVikhK6lGYy9FD9+xgcn1TM1vqmthc18TyDdv4cH0tS9dvZdn6Wpauq2XGkg3U1Dd94jE9C3MZGIRC/7J8BgY/83Mi5GRnEY1kEY0YOZFgOTt2P5qVlfCMci0tTl1TM7UNzWxraGZbY/xyU5vrjx/WmxHlpXv0PuyMgkBE0lpudoTcwgg9CnMZ3Mb1DO7OxtpGPlxf++/bulhYvLl4PY/PWs7unFOTnWX/DoqPQyOL7IhR39gSfLE3UdfY/jAe7elVlJt6QWBmJwO/ASLAn9z95u225wL3AYcD64AvufuSZNYkIhLPzOhekEP3ghwO7V+6w/b6pmaWb9hG9YZtbGtsprG5JXZrchpal5tbaGx2Gpq2u9/cQmPruhYnN5JFt5wI+TkRuuVk0y3auhz7mZ8TIS8aIT8nO7Y++u9tedmRpM1fnbQgMLMIcAdwIlANTDezSe4+N67ZZcAGd9/fzM4BfgF8KVk1iYjsrtzsCEN6FTKkV2HYpSTNng82smtjgIXuvsjdG4CHgQnbtZkA3BssPwocbxrKUESkUyUzCPoBy+LuVwfr2mzj7k3AJqDHdm0wsyvNrMrMqtasWZOkckVEMlMyg6DDuPtd7l7p7pW9evUKuxwRkbSSzCBYDvSPu18erGuzjZllAyXEDhqLiEgnSWYQTAeGmtlgM8sBzgEmbddmEvDlYPkLwEueaoMfiYikuKSdNeTuTWZ2FTCZ2Omjd7v7HDO7Cahy90nAn4H7zWwhsJ5YWIiISCdK6nUE7v408PR2634ct1wHfDGZNYiIyM6lxMFiERFJnpSbj8DM1gBL9/DhPYG1HVhOR1N9e0f17b2uXqPq23MD3b3N0y5TLgj2hplVtTcxQ1eg+vaO6tt7Xb1G1Zcc6hoSEclwCgIRkQyXaUFwV9gF7ILq2zuqb+919RpVXxJk1DECERHZUabtEYiIyHYUBCIiGS4tg8DMTjazBWa20Myua2N7rplNDLa/YWaDOrG2/mb2spnNNbM5ZvbNNtocZ2abzGxWcPtxW78riTUuMbN3g+euamO7mdntwfv3jpkd1om1HRj3vswys81m9q3t2nT6+2dmd5vZajObHbeuzMyeN7P3g5/d23nsl4M275vZl9tqk4TabjWz+cG/39/NrLSdx+70s5DkGm80s+Vx/46ntvPYnf69J7G+iXG1LTGzWe08tlPew73i7ml1Izau0QfAECAHeBuo2K7N14A7g+VzgImdWF9f4LBguQh4r436jgP+EeJ7uATouZPtpwLPAAYcCbwR4r/1SmIXyoT6/gHjgMOA2XHrbgGuC5avA37RxuPKgEXBz+7BcvdOqO2zQHaw/Iu2akvks5DkGm8E/jOBz8BO/96TVd92238F/DjM93Bvbum4R9ClZ0Zz9xXuPjNYrgHmseOEPV3dBOA+j5kGlJpZ3xDqOB74wN339ErzDuPuU4gNnBgv/nN2L/D5Nh56EvC8u6939w3A88DJya7N3Z/z2GRQANOIDRMfmnbev0Qk8ve+13ZWX/DdcTbwUEc/b2dJxyDosJnRki3okhoFvNHG5qPM7G0ze8bMDu7cynDgOTObYWZXtrE9kfe4M5xD+398Yb5/rfq4+4pgeSXQp402XeG9vJTYHl5bdvVZSLargu6ru9vpWusK798xwCp3f7+d7WG/h7uUjkGQEsysEPgb8C1337zd5pnEujsOBX4LPN7J5R3t7ocBpwBfN7Nxnfz8u2SxOS7GA//Xxuaw378deKyPoMudq21m1wNNwIPtNAnzs/C/wH7ASGAFse6Xruhcdr430OX/ntIxCLr8zGhmFiUWAg+6+2Pbb3f3ze6+JVh+GoiaWc/Oqs/dlwc/VwN/J7b7HS+R9zjZTgFmuvuq7TeE/f7FWdXaZRb8XN1Gm9DeSzO7GPgccH4QVDtI4LOQNO6+yt2b3b0F+GM7zx3qZzH4/jgTmNhemzDfw0SlYxB06ZnRgv7EPwPz3P22dtrs03rMwszGEPt36pSgMrMCMytqXSZ2UHH2ds0mARcFZw8dCWyK6wLpLO3+LyzM92878Z+zLwNPtNFmMvBZM+sedH18NliXVGZ2MvBdYLy717bTJpHPQjJrjD/udEY7z53I33synQDMd/fqtjaG/R4mLOyj1cm4ETur5T1iZxNcH6y7idiHHiCPWJfCQuBNYEgn1nY0sS6Cd4BZwe1U4CvAV4I2VwFziJ0BMQ34VCfWNyR43reDGlrfv/j6DLgjeH/fBSo7+d+3gNgXe0nculDfP2KhtAJoJNZPfRmx404vAu8DLwBlQdtK4E9xj700+CwuBC7ppNoWEutbb/0Mtp5Fty/w9M4+C534/t0ffL7eIfbl3nf7GoP7O/y9d0Z9wfq/tH7u4tqG8h7uzU1DTIiIZLh07BoSEZHdoCAQEclwCgIRkQynIBARyXAKAhGRDKcgEOlEwcio/wi7DpF4CgIRkQynIBBpg5ldYGZvBmPI/8HMIma2xcx+bbF5JF40s15B25FmNi1ubP/uwfr9zeyFYPC7mWa2X/DrC83s0WA+gAc7a+RbkfYoCES2Y2bDgC8BY919JNAMnE/siuYqdz8YeAW4IXjIfcD33H0EsSthW9c/CNzhscHvPkXsylSIjTj7LaCC2JWnY5P8kkR2KjvsAkS6oOOBw4HpwX/WuxEbMK6Ffw8u9gDwmJmVAKXu/kqw/l7g/4LxZfq5+98B3L0OIPh9b3owNk0wq9UgYGrSX5VIOxQEIjsy4F53//4nVpr9aLt2ezo+S33ccjP6O5SQqWtIZEcvAl8ws97w8dzDA4n9vXwhaHMeMNXdNwEbzOyYYP2FwCsem32u2sw+H/yOXDPL78wXIZIo/U9EZDvuPtfMfkhsVqksYiNOfh3YCowJtq0mdhwBYkNM3xl80S8CLgnWXwj8wcxuCn7HFzvxZYgkTKOPiiTIzLa4e2HYdYh0NHUNiYhkOO0RiIhkOO0RiIhkOAWBiEiGUxCIiGQ4BYGISIZTEIiIZLj/B5Df9naIL5YOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of training loss\n",
    "plt.plot(best['train_loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# This training loss curve indicates a low learning rate\n",
    "# https://towardsdatascience.com/useful-plots-to-diagnose-your-neural-network-521907fa2f45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdef9c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train_epoch 0/8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 7.93 GiB total capacity; 7.14 GiB already allocated; 33.12 MiB free; 7.20 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6af8ed5395d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mxlnet_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLNetSentimentTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlnet_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/ucsd-mle/xlnet/xlnet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, df, columns)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             train_acc, train_loss = self.__train_epoch(\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/ucsd-mle/xlnet/xlnet.py\u001b[0m in \u001b[0;36m__train_epoch\u001b[0;34m(self, data_loader, optimizer, scheduler, n_examples)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/xlnet/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1533\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/xlnet/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m             outputs = layer_module(\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0moutput_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/xlnet/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     ):\n\u001b[0;32m--> 516\u001b[0;31m         outputs = self.rel_attn(\n\u001b[0m\u001b[1;32m    517\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0moutput_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/xlnet/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;31m# core attention ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             attn_vec = self.rel_attn_core(\n\u001b[0m\u001b[1;32m    448\u001b[0m                 \u001b[0mq_head_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mk_head_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/xlnet/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# position based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ibnd,jbnd->bnij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_head\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_r_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_shift_bnij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 7.93 GiB total capacity; 7.14 GiB already allocated; 33.12 MiB free; 7.20 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Run training on the labeled crypto data - find the best sequence len\n",
    "#sequences=[256, 128, 64]\n",
    "sequences=[128, 64]\n",
    "history = []\n",
    "for seq in sequences:\n",
    "    xlnet_train = XLNetSentimentTrain(batchsize=64, max_len=seq)\n",
    "    history.append(xlnet_train.train(df, ['text', 'sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbd88d",
   "metadata": {},
   "source": [
    "# Sequence Length Selection\n",
    "We don't have enough GPU memory to train sequence length of 128, so will use 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ed5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hist in history:\n",
    "    print('Epochs: {}'.format(hist['epochs']))\n",
    "    print('Batchsize: {}'.format(hist['batchsize']))\n",
    "    print('Max len: {}'.format(hist['max_len']))\n",
    "    print(hist['classification_report'])\n",
    "    print()\n",
    "    \n",
    "# Max_len of 64 gives the best total accuracy and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c064ee",
   "metadata": {},
   "source": [
    "## Final Resultes\n",
    "The following parameters for XLNet training are giving the best results:\n",
    "- Epochs - 20\n",
    "- Batchsize - 48\n",
    "- Max_len - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6ee1c",
   "metadata": {},
   "source": [
    "## Try a Few Predictions\n",
    "Next we load the model file and try a few predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e09fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive_score': 0.06985868513584137, 'negative_score': 0.7878771424293518, 'neutral_score': 0.142264261841774, 'text': 'Bitcoin is the worst!', 'sentiment': 'negative'}\n",
      "{'positive_score': 0.6702779531478882, 'negative_score': 0.0223531574010849, 'neutral_score': 0.3073689043521881, 'text': 'Bitcoin is the best!', 'sentiment': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "from xlnet import XLNetSentiment\n",
    "\n",
    "model_file = './models/xlnet_model_batch48.bin'\n",
    "xlnet = XLNetSentiment(model_file, batchsize=1)\n",
    "\n",
    "text = \"Bitcoin is the worst!\"\n",
    "results = xlnet.predict(text)\n",
    "print(results)\n",
    "\n",
    "text = \"Bitcoin is the best!\"\n",
    "results = xlnet.predict(text)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
